<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: UNIX/Linux | OPS Notes By 枯木]]></title>
  <link href="http://kumu-Linux.github.io/blog/categories/unix-slash-linux/atom.xml" rel="self"/>
  <link href="http://kumu-Linux.github.io/"/>
  <updated>2014-06-23T18:02:04+08:00</updated>
  <id>http://kumu-Linux.github.io/</id>
  <author>
    <name><![CDATA[枯木]]></name>
    <email><![CDATA[1988.wulei@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[本地fsck修复qcow2]]></title>
    <link href="http://kumu-Linux.github.io/blog/2014/06/23/fsck-qcow2/"/>
    <updated>2014-06-23T16:36:00+08:00</updated>
    <id>http://kumu-Linux.github.io/blog/2014/06/23/fsck-qcow2</id>
    <content type="html"><![CDATA[<p>因为一些原因导致若干kvm虚拟机出现启动不了的情况，如下图：</p>

<!--more-->


<p><img src="http://kumu-Linux.github.io/images/boot_trouble.png"></p>

<p>这应该是文件系统破坏的问题，一般情况下还可以在虚拟机中fsck修复文件系统，但是这种情况在虚拟机中根本就没有机会fsck，所以想到通过外界方法对虚拟磁盘进行fsck。创建虚拟机使用的虚拟磁盘的类型是qcow2，开机无法fsck的话，可以通过如下两种方式:</p>

<ul>
<li>通过启动其它虚拟机的时候指定损坏虚拟磁盘启动再修复</li>
<li>通过qemu-nbd工具本地宿主机上修复qcow2</li>
</ul>


<p>这里介绍第二种方式，直接在宿主机上修复损坏qcow2磁盘，利用qemu-nbd把qcow2映射为网络设备<a href="http://en.wikipedia.org/wiki/Network_block_device">Network block device</a>。</p>

<h2>加载nbd</h2>

<p>``` bash</p>

<h1>modprobe nbd max_part=8 # max_part表示每个设备的分区，根据实际情况修改，默认为0</h1>

<h1>modinfo nbd   # 查看nbd相关信息</h1>

<p>filename:       /lib/modules/3.5.0-23-generic/kernel/drivers/block/nbd.ko
license:        GPL
description:    Network Block Device
srcversion:     B540FE0119F7C28B9D15C21
depends:      <br/>
intree:         Y
vermagic:       3.5.0-23-generic SMP mod_unload modversions
parm:           nbds_max:number of network block devices to initialize (default: 16) (int)
parm:           max_part:number of partitions per device (default: 0) (int)
parm:           debugflags:flags for controlling debug output (int)</p>

<h1>ls /dev/nbd* # 默认有16个nbd设备文件</h1>

<p>/dev/nbd0  /dev/nbd1  /dev/nbd10  /dev/nbd11  /dev/nbd12  /dev/nbd13
/dev/nbd14  /dev/nbd15  /dev/nbd2  /dev/nbd3  /dev/nbd4  /dev/nbd5<br/>
/dev/nbd6 /dev/nbd7  /dev/nbd8  /dev/nbd9
```</p>

<h2>映射损坏qcow2磁盘为nbd</h2>

<p>``` bash</p>

<h1>qemu-nbd --connect=/dev/nbd0 /data/0/41/disk.qcow2</h1>

<h1>映射disk.qcow2为本地的nbd0设备，qcow2需要为绝对路径</h1>

<h1>ls /dev/nbd0* # 映射虚拟磁盘有两个分区</h1>

<p>/dev/nbd0  /dev/nbd0p1  /dev/nbd0p2
```</p>

<p>本来准备修复了，但是发现发现之前的虚拟机分区是LVM设备，如果是正常分区直接修复就可以了，而LVM需要先LVM设备激活。</p>

<p>``` bash</p>

<h1>fdisk -l /dev/nbd0</h1>

<p>Disk /dev/nbd0: 32.2 GB, 32212254720 bytes
255 heads, 63 sectors/track, 3916 cylinders, total 62914560 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x00065194</p>

<pre><code> Device Boot      Start         End      Blocks   Id  System
</code></pre>

<p>/dev/nbd0p1   *          63      208844      104391   83  Linux
/dev/nbd0p2          208845    62910539    31350847+  8e  Linux LVM
```</p>

<h2>激活LVM</h2>

<h3>安装lvm</h3>

<p>``` bash</p>

<h1>mount /dev/nbd0p2 /mnt/ # 说明没有安装LVM</h1>

<p>mount: unknown filesystem type 'LVM2_member'</p>

<h1>apt-get install lvm2 -y</h1>

<p>```</p>

<h3>激活LVM</h3>

<p>默认状态可能LVM没有激活，如下：</p>

<p>``` bash</p>

<h1>lvdisplay</h1>

<p>  --- Logical volume ---
  LV Name                /dev/VolGroup00/LogVol00
  VG Name                VolGroup00
  LV UUID                VJkt2b-zSeD-DB23-XcfZ-1OHn-s0Ju-u7sXAN
  LV Write Access        read/write
  LV Status              NOT available
  LV Size                21.91 GiB
  Current LE             701
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto</p>

<p>  --- Logical volume ---
  LV Name                /dev/VolGroup00/LogVol01
  VG Name                VolGroup00
  LV UUID                kIOZsr-0uYd-FFud-yEnk-x6x7-1GxC-Q1yEOJ
  LV Write Access        read/write
  LV Status              NOT available
  LV Size                7.97 GiB
  Current LE             255
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
```</p>

<p>激活方式如下：</p>

<p>``` bash</p>

<h1>vgchange -ay /dev/VolGroup00</h1>

<p>  2 logical volume(s) in volume group "VolGroup00" now active</p>

<h1>ls /dev/VolGroup00/*</h1>

<p>/dev/VolGroup00/LogVol00  /dev/VolGroup00/LogVol01
```</p>

<h2>修复指定分区</h2>

<p>``` bash</p>

<h1>fsck -y /dev/VolGroup00/LogVol0</h1>

<p>... ...
Free blocks count wrong (5069553, counted=5070543).
Fix? yes</p>

<p>/dev/mapper/VolGroup00-LogVol00: <strong><strong><em> FILE SYSTEM WAS MODIFIED </em></strong></strong>
/dev/mapper/VolGroup00-LogVol00: 79036/5744640 files (0.7% non-contiguous), 672049/5742592 blocks
```</p>

<p>如上结果，最终修复磁盘成功。</p>

<h2>取消映射</h2>

<p>修复完成之后取消nbd映射，开启虚拟机即可，取消映射方法如下命令。</p>

<p>``` bash</p>

<h1>qemu-nbd --disconnect /dev/nbd0</h1>

<p>/dev/nbd0 disconnected
```</p>

<p>修复之后，顺利启动相关虚拟机，推荐开机之后再<code>shutdown -F now</code>强制修复一下，以防万一。</p>

<h2>参考</h2>

<ul>
<li><a href="http://www.randomhacks.co.uk/how-to-recover-fsck-a-qcow2-file/">How to recover a qcow2 file using fsck</a></li>
</ul>


<p>--EOF--</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ubuntu14.04重启网卡不生效]]></title>
    <link href="http://kumu-Linux.github.io/blog/2014/05/28/ubuntu-network-br0/"/>
    <updated>2014-05-28T11:38:00+08:00</updated>
    <id>http://kumu-Linux.github.io/blog/2014/05/28/ubuntu-network-br0</id>
    <content type="html"><![CDATA[<p>Stopping or restarting the networking job is not supported.<br/>
Use ifdown &amp; ifup to reconfigure desired interface.</p>

<!--more-->


<p>Ubuntu14.04修改配置，重启网卡没有生效，出现如下问题：</p>

<p>``` bash</p>

<h1>cat /etc/issue</h1>

<p>Ubuntu 14.04 LTS \n \l</p>

<h1>service  networking restart</h1>

<p>stop: Job failed while stopping
start: Job is already running: networking</p>

<h1>tail -f /var/log/upstart/networking.log</h1>

<p>Stopping or restarting the networking job is not supported.
Use ifdown &amp; ifup to reconfigure desired interface.
```</p>

<p>从以上日志内容可以看出，传统的service重启和停止网络已经不再支持了，需要通过使用ifdown &amp; ifup来实现相应的操作。</p>

<ul>
<li>重启指定网卡</li>
</ul>


<p>``` bash</p>

<h1>ifdown eth0 &amp;&amp; ifup eth0</h1>

<p>```</p>

<ul>
<li>重启除lo网卡的所有网卡</li>
</ul>


<p>``` bash</p>

<h1>ifdown --exclude=lo -a &amp;&amp; sudo ifup --exclude=lo -a</h1>

<p>```</p>

<ul>
<li>配置桥接</li>
</ul>


<p>``` bash</p>

<h1>apt-get install bridge-utils</h1>

<h1>cat /etc/network/interfaces</h1>

<p>auto lo
iface lo inet loopback</p>

<p>auto eth0
iface eth0 inet manual</p>

<p>auto br0
iface br0 inet static
address 192.168.0.10
netmask 255.255.255.0
gateway 192.168.0.1
bridge_ports eth0
bridge_stp off
bridge_fd 0
bridge_maxwait 0
dns-nameservers 192.168.0.1</p>

<h1>ifup br0</h1>

<h1>brctl  show</h1>

<p>bridge name bridge id       STP enabled interfaces
br0     8000.02000a0080e1   no      eth0
```</p>

<ul>
<li><a href="https://bugs.launchpad.net/ubuntu/+source/ifupdown/+bug/1301015">Networking does not restart</a></li>
</ul>


<p>--EOF--</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ssh MaxAuthTries]]></title>
    <link href="http://kumu-Linux.github.io/blog/2014/05/21/ssh-maxauthtries/"/>
    <updated>2014-05-21T23:05:00+08:00</updated>
    <id>http://kumu-Linux.github.io/blog/2014/05/21/ssh-maxauthtries</id>
    <content type="html"><![CDATA[<p>新建了一个Ubuntu14.04的虚拟机，使用xshell登陆，刚输入用户名后却直接抛出了 <code>Too many authentication failures for username</code> 的错误。ssh登陆失败尝试次数和<code>MaxAuthTries</code>值相关，直接<code>man sshd_config</code>获取该参数说明，得到如下内容：</p>

<!--more-->


<blockquote><p>MaxAuthTries</p>

<pre><code>Specifies the maximum number of authentication attempts permitted per connection.  
Once the number of failures reaches half this value, 
additional failures are logged.  The default is 6.
</code></pre></blockquote>

<p>让我很诧异的是，关键尼玛我还没有输入密码什么的啊，只是输入一个用户名就报错了。于是测试虚拟机本地ssh登陆，登陆正常，其它Linux主机登陆测试也正常，再测试xshell，依然是输入用户名之后报之前同样的错误。ssh本地<code>debug</code>模式再看下过程</p>

<p><code>bash
$ ssh -v 127.0.0.1
... ...
debug1: Trying private key: /home/test/.ssh/id_rsa
debug1: Trying private key: /home/test/.ssh/id_dsa
debug1: Trying private key: /home/test/.ssh/id_ecdsa
debug1: Trying private key: /home/test/.ssh/id_ed25519
debug1: Next authentication method: password
test@127.0.0.1's password:
... ...
</code></p>

<p>debug模式看到这里，我自己有点明白了，ssh验证过程是先尝试私钥再进行密码，查看Xagent开启了3个私钥agent，所以3次没有匹配到私钥之后就断开报错了。<code>MaxAuthTries</code>值默认为6，但是<code>Once the number of failures reaches half this value</code>尝试次数达到设定值一半之后就不能再尝试了。</p>

<p>--EOF--</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux性能优化--CPU[备忘]]]></title>
    <link href="http://kumu-Linux.github.io/blog/2014/04/21/performance-cpu/"/>
    <updated>2014-04-21T17:52:00+08:00</updated>
    <id>http://kumu-Linux.github.io/blog/2014/04/21/performance-cpu</id>
    <content type="html"><![CDATA[<p>Linux性能相关可以从以下几方面入手：</p>

<ul>
<li>CPU</li>
<li>Memory</li>
<li>IO</li>
<li>Network</li>
</ul>


<!--more-->


<p>这些子系统之间关系相互彼此依赖的，任何一个高负载都会导致其他子系统出现问题，比如：</p>

<ul>
<li>大量的页请求导致内存队列的拥塞</li>
<li>网卡的大吞吐量可能导致更多的CPU开销</li>
<li>大量的CPU开销又尝试更多的内存使用请求</li>
<li>大量来自内存的磁盘写请求可能导致更多的cpu以及IO问题</li>
</ul>


<h2>CPU</h2>

<p>主要关注点在运行队列、利用率、上下文切换</p>

<ul>
<li>Run Queues - 每个处理器应该运行队列不超过1-3个线程，一个双核处理器应该运行队列不要超过6个线程</li>
<li>CPU Utiliation - 如果一个CPU被充分使用，利用率分类之间均衡的比例应该是：

<ul>
<li>65% - 70% User Time</li>
<li>30% - 35% System Time</li>
<li>0% - %5 Idle Time</li>
</ul>
</li>
<li>Context Switches - 上下文切换的数目直接关系到CPU的使用率，如果CPU利用率保持在上述均衡状态时，大量的上下文切换是正常的</li>
</ul>


<p><code>bash
$ vmstat 2
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 4  0  42808 130596  70836 23084420    0    0     0     5    0    0  5  2 93  0  0
 8  0  42808 129388  70836 23084904    0    0     0    30 10987 80554  9  3 88  0  0
 6  0  42808 137428  70828 23076148    0    0     0    26 11129 80587  9  3 88  0  0
</code></p>

<ul>
<li><code>r</code> The amount of threads in the run queue. These are threads that are runnable, but the CPU is not available to execute them.

<ul>
<li>当前<code>运行队列中线程的数目</code>.代表线程处于可运行状态,但CPU还未能执行.</li>
</ul>
</li>
<li><code>b</code> This is the number of processes blocked and waiting on IO requests to finish.

<ul>
<li>当前<code>进程阻塞并等待IO请求完成的数目</code></li>
</ul>
</li>
<li><code>in</code> This is the number of interrupts being processed.

<ul>
<li>当前<code>中断</code>被处理的数目</li>
</ul>
</li>
<li><code>cs</code> This is the number of context switches currently happening on the system.

<ul>
<li>当前kernel system中,发生<code>上下文切换</code>的数目</li>
</ul>
</li>
<li><code>us</code> This is the percentage of user CPU utilization.

<ul>
<li>CPU利用率的百分比</li>
</ul>
</li>
<li><code>sys</code> This is the percentage of kernel and interrupts utilization.

<ul>
<li><code>内核和中断利用率的百分比</code></li>
</ul>
</li>
<li><code>wa</code> This is the percentage of idle processor time due to the fact that ALL runnable threads are blocked waiting on IO.

<ul>
<li>所有<code>可运行状态线程被阻塞在等待IO请求的百分比</code></li>
</ul>
</li>
<li><code>id</code> This is the percentage of time that the CPU is completely idle.

<ul>
<li>CPU空闲时间的百分比</li>
</ul>
</li>
</ul>


<p><code>bash
$ mpstat -P ALL 1   # 查看单个cpu利用率情况，同`sar -P ALL 1`
16时17分05秒  CPU   %user   %nice    %sys %iowait    %irq   %soft  %steal   %idle    intr/s
16时17分07秒  all    2.62    0.00    0.29    0.10    0.04    0.33    0.00   96.61  11159.00
16时17分07秒    0    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00   1000.50
16时17分07秒    1    0.00    0.00    0.00    1.01    0.00    0.00    0.00   98.99     26.00
16时17分07秒    2    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00      0.00
16时17分07秒    3    0.50    0.00    0.00    0.00    0.00    0.00    0.00   99.50      0.00
16时17分07秒    4    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00      0.00
16时17分07秒    5    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00      0.00
</code></p>

<p><code>bash
$ while :; do ps -eo pid,ni,pri,pcpu,psr,comm | \
grep 'mysqld'; sleep 1 ;done # ps通过查看psr队列获取进程占用哪个cpu
</code></p>

<p>top也可以实时查看占用哪个cpu
<code>bash
$ top -p `pgrep mysql | xargs | tr " " ","` # 执行如上命令之后输入`f`,然后输入`j`回车即可
</code></p>

<p><code>pri</code>优先级动态值，<code>ni</code>为静态值，root用户可以调高nice优先级[-20~19]，-20为优先级最高，普通用户只能调低优先级，两者关系：<code>pri[new]=pri[old]+nice</code></p>

<p>监控CPU性能由以下几个部分组成：</p>

<ul>
<li>1、检查system的运行队列，以及确定不要超过每个处理器3个可运行状态线程的限制</li>
<li>2、确定CPU利用率中user/system比例维持在70/30</li>
<li>3、当CPU开销更多的时间在system mode，那就说明已经超负荷并且应该尝试重新调度优先级</li>
<li>4、当I/O处理增长，CPU相应的应用将会受到影响</li>
</ul>


<p>--EOF--</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[svn and git Server备忘]]></title>
    <link href="http://kumu-Linux.github.io/blog/2013/12/09/svn-git/"/>
    <updated>2013-12-09T13:58:00+08:00</updated>
    <id>http://kumu-Linux.github.io/blog/2013/12/09/svn-git</id>
    <content type="html"><![CDATA[<h2><u>Git Server with ssh</u></h2>

<!--more-->


<ul>
<li>Server</li>
</ul>


<p><code>bash
useradd -s /usr/bin/git-shell git   //创建git用户
git init --bare /home/git/testrepo  //初始化名为testrepo，Server端操作
mkdir /home/git/.ssh -p
vim .ssh/authorized_keys            //加入客户端ssh公钥，设置ssh公钥认证
chmod 700 /home/git/.ssh/
chmod 400 /home/git/.ssh/authorized_keys
chown git:git -R /home/git
</code></p>

<p>注意：如果是root用户执行的命令，需要修改权限如下
<code>
chown -R git:git testrepo
</code></p>

<ul>
<li>Client</li>
</ul>


<p><code>bash
git clone git@sevrer_ip:/home/git/testrepo  //克隆repo
</code></p>

<p>具体操作<br/>
<code>bash
cd testrepo                         //进入本地版本库
echo "hello" &gt;&gt; test                //新建测试文件
git add test                        //添加到git缓存
git commit -m "first commit" test   //本地提交
git push -u origin master           //提交给远程服务器
git pull                            //客户端拉取数据
</code></p>

<h2><u>Svn Server with apache &amp;&amp; ldap</u></h2>

<p><code>bash
yum install subversion mod_dav_svn -y
</code></p>

<p>yum安装后会生成subversion.conf并添加相应模块配置
``` bash</p>

<h1>grep LoadModule /etc/httpd/conf.d/subversion.conf</h1>

<p>LoadModule dav_svn_module     modules/mod_dav_svn.so
LoadModule authz_svn_module   modules/mod_authz_svn.so
```</p>

<p>svn创建库<br/>
<code>bash
svnadmin create --fs-type fsfs /var/www/svn
chown apache:apache -R /var/www/svn
</code></p>

<p>设置ldap认证<br/>
``` bash</p>

<h1>grep -vE '<sup>$|<sup>#'</sup></sup> /etc/httpd/conf.d/subversion.conf</h1>

<p>LoadModule dav_svn_module     modules/mod_dav_svn.so
LoadModule authz_svn_module   modules/mod_authz_svn.so
<Location /svn></p>

<pre><code>DAV svn 
SVNPath /var/www/svn
AuthBasicProvider ldap
AuthType Basic
AuthzLDAPAuthoritative off
AuthName "Please provide your windows login credentials to continue."
AuthLDAPURL "ldap://ldap_ip/ou=users,ou=test,dc=intranet,dc=test,dc=com?sAMAccountName" NONE
AuthLDAPBindDN "test@intranet.test.com"
AuthLDAPBindPassword password 
require valid-user
</code></pre>

<p></Location>
```</p>

<p>启动apache<br/>
<code>
service httpd start
</code></p>

<p>浏览器登陆<br/>
<a href="http://svn_ip/svn">http://svn_ip/svn</a></p>
]]></content>
  </entry>
  
</feed>
